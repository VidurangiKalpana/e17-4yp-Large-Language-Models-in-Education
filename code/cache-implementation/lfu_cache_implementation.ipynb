{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a99c1cb-f7ec-4a9e-9bf1-0fe415ce1b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e9e831d-a62b-4b3e-823a-c8094d3cfd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python311\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator KNeighborsClassifier from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "model = joblib.load('questions-categorizer-v2-KNeighborsClassifier.model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "349e00a3-0e76-450f-94cc-67654bc33f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Question Response  Access Count\n",
      "0                               0\n",
      "1                               0\n",
      "2                               0\n",
      "3                               0\n"
     ]
    }
   ],
   "source": [
    "# Initialize fixed size dataframe to setup cache (LFU)\n",
    "num_rows = 4  # Size of the cache\n",
    "columns = ['Question', 'Response', 'Access Count']\n",
    "# Create a list of dictionaries with default values\n",
    "data = [{'Question': '', 'Response': '', 'Access Count': 0} for _ in range(num_rows)]\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "cache_for_VM = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "print(cache_for_VM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1896e5f5-a8e2-42d7-bb6f-7ca02c733965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resp 23\n"
     ]
    }
   ],
   "source": [
    "# New values for the row\n",
    "new_values = {'Question': 'How does TLB caching improve virtual memory performance?', 'Response': 'Resp 23', 'Access Count': 1}\n",
    "\n",
    "# Change the values using .loc[]\n",
    "cache_for_VM.loc[1] = new_values\n",
    "\n",
    "print(cache_for_VM.iloc[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "27e9638d-8c8a-459e-ba9b-8db2f3fbf0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "# encoded cache files\n",
    "embeddings_cache_for_VM = embedder.encode(cache_for_VM['Question'])\n",
    "print(len(embeddings_cache_for_VM[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ee5c28b1-6a5a-4f04-93fb-5389976ddc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_the_response(new_request, category):\n",
    "  encoded_new_request = embedder.encode(new_request)\n",
    "\n",
    "  response = cache_handler(new_request, encoded_new_request, category)\n",
    "  return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3d2cfcc1-177c-4e04-bdbe-390f5040db55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cache_handler(request, encoded_request, category):\n",
    "  if category == \"vm\":\n",
    "    cos_sim = util.cos_sim(embeddings_cache_for_VM, encoded_request)\n",
    "    if (max(cos_sim) > 0.75):\n",
    "      print(\"* * * * * * * From Cache * * * * * * * \")\n",
    "      print(cos_sim.argmax().item())\n",
    "      return cache_for_VM.iloc[cos_sim.argmax().item()][1]\n",
    "    else:\n",
    "      return call_API(request)\n",
    "  # add other categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "81931f6d-a001-4bf8-af8b-dbee942dbdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_API(request):\n",
    "  print(\"* * * * * * * Calling API * * * * * * * \")\n",
    "  mock_resp = \"API response for -> \" + request\n",
    "  return mock_resp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b6c946bb-e07c-4bac-b1f8-95f8346f216b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = \"can you please tell me how can we improve performances of cache using TLB?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2b640330-c67f-4999-a860-bb3a9478b07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* * * * * * * From Cache * * * * * * * \n",
      "1\n",
      "Resp 23\n"
     ]
    }
   ],
   "source": [
    "category = \"vm\"\n",
    "response_for_test_sentence = give_the_response(test_sentence, category)\n",
    "print(response_for_test_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
